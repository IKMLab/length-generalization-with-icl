evaluation_strategy: steps
gradient_accumulation_steps: 1
eval_gradient_accumulation_steps: 1
learning_rate: 3.0e-4
weight_decay: 0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 8.0e-08
max_grad_norm: 1.0
max_steps: 50000
warmup_ratio: 0.03
logging_steps: 10
save_strategy: steps
save_steps: 500
save_total_limit: 1
metric_for_best_model: loss
eval_steps: 100
per_device_train_batch_size: 64
per_device_eval_batch_size: 64